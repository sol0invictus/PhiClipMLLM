model:
  text_model: microsoft/Phi-3-mini-4k-instruct
  vision_model: openai/clip-vit-large-patch14
  adapter_dim: 1024

dtype: torch.bfloat16

checkpoint:
  output_dir: C:/Users/sunny/Desktop/mllm/checkpoint_dir

phase_one:
  annotation_file: C:/coco/labels/annotations/captions_train2017.json
  image_directory: C:/coco/train2017


training_args:
  num_train_epochs: 1
  learning_rate: 0.001
  batch_size: 8
  save_steps: 10000
